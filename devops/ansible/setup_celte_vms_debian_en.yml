---
- name: Configure Debian/Ubuntu VMs for Celte System (Part 1 - Base Setup)
  hosts: celte_vms # This part targets all VMs for base setup
  become: yes
  vars:
    git_repo_url: https://github.com/celte-team/celte-system.git
    git_clone_dest: /opt/celte-system

  tasks:
    - name: Update APT cache and install prerequisites for Docker and LSB
      ansible.builtin.apt:
        name:
          - ca-certificates
          - curl
          - gnupg
          - lsb-release
          - python3-pip
        state: present
        update_cache: yes

    - name: Create directory for APT GPG keys
      ansible.builtin.file:
        path: /etc/apt/keyrings
        state: directory
        mode: '0755'

    - name: Add Docker's official GPG key
      ansible.builtin.shell:
        cmd: curl -fsSL https://download.docker.com/linux/{{ ansible_facts.distribution | lower }}/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg
        creates: /etc/apt/keyrings/docker.gpg
      register: add_docker_gpg_key

    - name: Ensure Docker GPG key has correct permissions
      ansible.builtin.file:
        path: /etc/apt/keyrings/docker.gpg
        mode: '0644'

    - name: Get system architecture (dpkg)
      ansible.builtin.command: dpkg --print-architecture
      register: dpkg_arch
      changed_when: false
      check_mode: no

    - name: Get OS release codename
      ansible.builtin.shell:
        cmd: . /etc/os-release && echo "$VERSION_CODENAME"
      register: os_release_info
      changed_when: false
      check_mode: false

    - name: Add Docker APT repository
      ansible.builtin.apt_repository:
        repo: "deb [arch={{ dpkg_arch.stdout }} signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/{{ ansible_facts.distribution | lower }} {{ os_release_info.stdout | trim }} stable"
        state: present
        filename: docker

    - name: Install required packages (Docker, Git, Python libs, ACL, UFW)
      ansible.builtin.apt:
        name:
          - docker-ce
          - docker-ce-cli
          - containerd.io
          - docker-buildx-plugin
          - docker-compose-plugin
          - git
          - acl
          - ufw
        state: present
        update_cache: yes

    - name: Clone Celte System Git repository
      ansible.builtin.git:
        repo: "{{ git_repo_url }}"
        dest: "{{ git_clone_dest }}"
        version: main

    - name: Install 'colorama' Python package via APT
      ansible.builtin.apt:
        name: python3-colorama
        state: present

    - name: Start and enable Docker service
      ansible.builtin.systemd:
        name: docker
        state: started
        enabled: yes

    - name: Allow '{{ ansible_user }}' to manage Docker via socket
      ansible.builtin.acl:
        path: /var/run/docker.sock
        entity: "{{ ansible_user }}"
        etype: user
        permissions: rw
        state: present
      when: ansible_facts.services['docker.service'] is defined and ansible_facts.services['docker.service'].state == 'running'

    - name: Install UFW (ensures it is installed)
      ansible.builtin.apt:
        name: ufw
        state: present

    - name: Configure and enable UFW (firewall)
      ansible.builtin.ufw:
        state: enabled
        policy: deny

    - name: Allow necessary ports through UFW for base system
      ansible.builtin.ufw:
        rule: allow
        port: "{{ item.port }}"
        proto: "{{ item.proto | default('tcp') }}"
      loop:
        - { port: "22", proto: "tcp" } # SSH
        - { port: "6650", proto: "tcp" }
        - { port: "3000", proto: "tcp" }
        - { port: "6379", proto: "tcp" }
        - { port: "5540", proto: "tcp" }

# ---------------------------------------------------------------------------
# Play 2: Kubernetes (K3s) Prerequisites
# ---------------------------------------------------------------------------
- name: Kubernetes (K3s) Prerequisites
  hosts: k3s_cluster # Targets all master and agent nodes
  become: yes
  tasks:
    - name: Disable swap
      ansible.builtin.command: swapoff -a
      when: ansible_swaptotal_mb > 0
      changed_when: true

    - name: Remove swap from /etc/fstab
      ansible.builtin.replace:
        path: /etc/fstab
        regexp: '^\s*([^#\s]+\s+[^#\s]+\s+swap\s+.*)$'
        replace: '# \1'
      when: ansible_swaptotal_mb > 0

    - name: Ensure br_netfilter module is loaded
      community.general.modprobe:
        name: br_netfilter
        state: present

    - name: Configure Kubernetes sysctl settings
      ansible.posix.sysctl:
        name: "{{ item.name }}"
        value: "{{ item.value }}"
        sysctl_file: /etc/sysctl.d/99-kubernetes-k3s.conf
        state: present
        reload: yes
      loop:
        - { name: "net.bridge.bridge-nf-call-iptables", value: "1" }
        - { name: "net.ipv4.ip_forward", value: "1" }
        - { name: "net.bridge.bridge-nf-call-ip6tables", value: "1" }

    - name: Allow K3s required ports through UFW
      ansible.builtin.ufw:
        rule: allow
        port: "{{ item.port }}"
        proto: "{{ item.proto | default('tcp') }}"
        comment: "{{ item.comment }}"
      loop:
        # K3s Server Ports (on master)
        - { port: "6443", proto: "tcp", comment: "K3s API Server (master)" } # All nodes need to reach this on master
        - { port: "2379", proto: "tcp", comment: "K3s etcd client (master, if using embedded etcd HA)" } # Not strictly needed for agents for single master
        - { port: "2380", proto: "tcp", comment: "K3s etcd peer (master, if using embedded etcd HA)" } # Not strictly needed for agents for single master
        # K3s Agent Ports
        - { port: "10250", proto: "tcp", comment: "Kubelet API (all nodes)" }
        # Flannel VXLAN (default CNI for K3s)
        - { port: "8472", proto: "udp", comment: "K3s Flannel VXLAN" }
      when: inventory_hostname in groups['k3s_master'] or item.port == '6443' or item.port == '10250' or item.port == '8472'

    - name: Reload UFW to apply new rules
      ansible.builtin.command: ufw reload
      changed_when: true

# ---------------------------------------------------------------------------
# Play 3: Install K3s Server (Master Node)
# ---------------------------------------------------------------------------
- name: Install K3s Server (Master Node)
  hosts: k3s_master
  become: yes
  tasks:
    - name: Install k3s server
      ansible.builtin.shell:
        cmd: "curl -sfL https://get.k3s.io | sh -s - server --cluster-init" # --cluster-init for first master, enabling etcd
      args:
        creates: /etc/systemd/system/k3s.service

    - name: Wait for k3s server to be ready
      ansible.builtin.wait_for:
        host: "{{ ansible_default_ipv4.address | default(ansible_host) }}"
        port: 6443
        delay: 20
        timeout: 300
        state: started

    - name: Wait for k3s server node token to be available
      ansible.builtin.wait_for:
        path: /var/lib/rancher/k3s/server/node-token
        timeout: 60

    - name: Read the k3s node token from master
      ansible.builtin.command: cat /var/lib/rancher/k3s/server/node-token
      register: k3s_node_token_raw
      changed_when: false

    - name: Set k3s join token fact for other hosts to use
      ansible.builtin.set_fact:
        k3s_join_token: "{{ k3s_node_token_raw.stdout | trim }}"

# ---------------------------------------------------------------------------
# Play 4: Install K3s Agents (Worker Nodes)
# ---------------------------------------------------------------------------
- name: Install K3s Agents (Worker Nodes)
  hosts: k3s_agents
  become: yes
  tasks:
    - name: Install k3s agent
      ansible.builtin.shell:
        cmd: "curl -sfL https://get.k3s.io | sh -s -"
      environment:
        K3S_URL: "https://{{ hostvars[groups['k3s_master'][0]]['ansible_host'] | default(groups['k3s_master'][0]) }}:6443"
        K3S_TOKEN: "{{ hostvars[groups['k3s_master'][0]]['k3s_join_token'] }}"
      args:
        creates: /etc/systemd/system/k3s-agent.service

# ---------------------------------------------------------------------------
# Play 5: Post-Installation (Fetch Kubeconfig)
# ---------------------------------------------------------------------------
- name: Post-Installation (Fetch Kubeconfig)
  hosts: k3s_master # Run this on the master node
  become: yes # k3s.yaml is root-owned
  tasks:
    - name: Fetch kubeconfig file from k3s master
      ansible.builtin.fetch:
        src: /etc/rancher/k3s/k3s.yaml
        dest: "./k3s_config-{{ inventory_hostname }}.yaml" # Saves to your Ansible controller machine
        flat: yes
        validate_checksum: yes

    - name: Display Kubeconfig instructions
      ansible.builtin.debug:
        msg:
          - "K3s cluster setup initiated."
          - "Kubeconfig file has been fetched to your Ansible control machine as ./k3s_config-{{ inventory_hostname }}.yaml"
          - "To use kubectl with this cluster:"
          - "1. Ensure kubectl is installed on your local machine."
          - "2. Update the server IP in the fetched k3s_config-{{ inventory_hostname }}.yaml if it points to an internal/unreachable IP (e.g., 127.0.0.1). It should point to {{ hostvars[inventory_hostname]['ansible_host'] | default(inventory_hostname) }}."
          - "3. Set the KUBECONFIG environment variable: export KUBECONFIG=$(pwd)/k3s_config-{{ inventory_hostname }}.yaml"
          - "4. Test with: kubectl get nodes"
      delegate_to: localhost # Show this message on your Ansible controller
      run_once: true # Ensure this message appears only once

  handlers: # Handlers from your original playbook
    - name: Reload UFW (if necessary per ufw module logic)
      ansible.builtin.ufw:
        state: reloaded